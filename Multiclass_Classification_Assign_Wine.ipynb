{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/WuJPduM14Rd/cpTOTKUY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajgit-123/MyProject/blob/master/Multiclass_Classification_Assign_Wine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Regression Problem\n",
        "\n"
      ],
      "metadata": {
        "id": "CDKA7TlNkuCP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJ7DQNBhk_DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ynfyi4C_nLPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYoE2xCgkaR7"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "##loading CSV from drive\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "train_file_path='/content/drive/MyDrive/ADSA010/Multiclass-Classification-Assign/train.csv'\n",
        "test_file_path='/content/drive/MyDrive/ADSA010/Multiclass-Classification-Assign/test.csv'\n",
        "#Creating dataframe\n",
        "train_df =pd.read_csv(train_file_path)\n",
        "test_df=pd.read_csv(test_file_path)\n",
        "\n",
        "#check df Head\n",
        "train_df.head()\n",
        "\n",
        "#Finding percentage of null values\n",
        "def percent_null(df):\n",
        "  percentage_ofnull=(train_df.isnull().sum()*100)/len(df)\n",
        "  return percentage_ofnull\n",
        "print(percent_null(train_df))\n",
        "def percent_null(df):\n",
        "  percentage_ofnull=(test_df.isnull().sum()*100)/len(df)\n",
        "  return percentage_ofnull\n",
        "print(percent_null(test_df))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_df.head()\n",
        "train_df.describe()\n",
        "#convert the String to numerical Data for column WINETYPE\n",
        "train_df.replace({'white': 1, 'red': 0}, inplace=True)\n",
        "test_df.replace({'white': 1, 'red': 0}, inplace=True)"
      ],
      "metadata": {
        "id": "9feFH2iIoGEO"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the distribution of the fetures given\n",
        "train_df.hist(bins=20, figsize=(10, 10))\n",
        "plt.show()\n",
        "# train_df.hist(bins=20, figsize=(10, 10))\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "_KWIBuRipqQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(train_df['quality'], train_df['alcohol'])\n",
        "plt.xlabel('quality')\n",
        "plt.ylabel('alcohol')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-hkwQECHp303"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the data in heatmap to check correlation of fetures\n",
        "import seaborn as sbn\n",
        "plt.figure(figsize=(12, 12))\n",
        "sbn.heatmap(train_df.corr() > 0.7, annot=True, cbar=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "plJtA-gaqNso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove one of the highly correlated feature\n",
        "train_df = train_df.drop('total sulfur dioxide', axis=1)\n",
        "test_df = test_df.drop('total sulfur dioxide', axis=1)\n",
        "#identify and group the features and target features\n",
        "X_train = train_df.drop(columns=['quality'])\n",
        "y_train = train_df['quality']\n",
        "\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "print(test_df.describe)"
      ],
      "metadata": {
        "id": "1UOh0LvAyJYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "col_transformer=ColumnTransformer(transformers = [('encode', OneHotEncoder() , [2])], remainder= 'passthrough')\n",
        "X = col_transformer.fit_transform(X)\n",
        "print(X)"
      ],
      "metadata": {
        "id": "v392CcrUzTj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#datset split to train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
        "print(\"X:\",X.shape)\n",
        "print(\"y:\",y.shape)\n",
        "print(\"X_train:\",X_train.shape)\n",
        "print(\"X_test:\",X_test.shape)\n",
        "print(\"y_train:\",y_train.shape)\n",
        "print(\"y_test:\",y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT-c59PM3wjo",
        "outputId": "482edc83-1705-4dfc-8f98-ee6907de5436"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: (4873, 14)\n",
            "y: (4873,)\n",
            "X_train: (3898, 14)\n",
            "X_test: (975, 14)\n",
            "y_train: (3898,)\n",
            "y_test: (975,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model selection and fitting the model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model=LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "25xsYkSq4RsP",
        "outputId": "06631208-37de-43b9-995f-7b235ab37a4b"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find the prediction of target feature\n",
        "y_pred=model.predict(X_test)\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "id": "qv5b6Gp14orr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate r2_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-jsTNAn42d6",
        "outputId": "96537dbd-d145-4992-cbde-bbcc50ecf307"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2709099924843472"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.drop(columns=['quality'])\n",
        "y_train = train_df['quality']\n",
        "\n",
        "# Step 4: Train a Multiclass Classification Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model (optional)\n",
        "# y_pred_train = rf_classifier.predict(X_train)\n",
        "# print(\"Train F1 Score:\", f1_score(y_train, y_pred_train, average='weighted'))\n",
        "\n",
        "# Step 5: Make Predictions on the Test Set\n",
        "# Ensure that the columns of the test dataset match the columns of the training dataset\n",
        "test_df = train_df[X_train.columns]\n",
        "#print (X_train)\n",
        "\n",
        "test_predictions = classifier.predict(test_df)\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "print(r2_score(y_train, test_predictions))\n",
        "\n",
        "# Step 6: Create the Submission File\n",
        "submission_df = pd.DataFrame({'ID': test_df['ID'], 'quality': test_predictions})\n",
        "submission_df.to_csv('Multiclass_Classification_submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W_269L8EfAh",
        "outputId": "569c57a3-77d3-4a39-9c73-8098581d06da"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "Submission file created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df = pd.DataFrame({'ID': train_df['ID'], 'quality': pred})\n",
        "sub_df.to_csv('Multiclass_submission.csv')"
      ],
      "metadata": {
        "id": "C9puk7UNAYLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop('total sulfur dioxide', axis=1)"
      ],
      "metadata": {
        "id": "p65xV6Z1qr9y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df['best quality'] = [1 if x > 5 else 0 for x in train_df.quality]"
      ],
      "metadata": {
        "id": "x50b3H4dq00n"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df.replace({'white': 1, 'red': 0}, inplace=True)"
      ],
      "metadata": {
        "id": "W_s7wf6Uq7GR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = train_df.drop(['quality', 'best quality'], axis=1)\n",
        "target = train_df['best quality']\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(\n",
        "    features, target, test_size=0.2, random_state=40)\n",
        "\n",
        "xtrain.shape, xtest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJMfgNplrFg-",
        "outputId": "559fa467-0a3f-418b-e6a9-8e340e519e17"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3898, 12), (975, 12))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model=LogisticRegression()\n",
        "model.fit(xtrain,ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "NI5-5Wr4rgeu",
        "outputId": "36417a28-6091-4623-febc-0871544dd2d5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "he steps involved in the preprocessing is appended below:\n",
        "# Step 2: Preprocess the Data\n",
        "# Encode categorical variable 'wine type'\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['wine type'] = label_encoder.fit_transform(train_df['wine type'])\n",
        "test_df['wine type'] = label_encoder.transform(test_df['wine type'])\n",
        "\n",
        "For your information, the entire code snippet is given below:\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Step 1: Load and Explore the Data\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Explore the data\n",
        "print(\"Train data shape:\", train_df.shape)\n",
        "print(\"Test data shape:\", test_df.shape)\n",
        "print(train_df.head())\n",
        "\n",
        "# Step 2: Preprocess the Data\n",
        "# Encode categorical variable 'wine type'\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['wine type'] = label_encoder.fit_transform(train_df['wine type'])\n",
        "test_df['wine type'] = label_encoder.transform(test_df['wine type'])\n",
        "\n",
        "# Handle missing values if any (not shown here)\n",
        "\n",
        "# Step 3: Split the Data\n",
        "X_train = train_df.drop(columns=['quality'])\n",
        "y_train = train_df['quality']\n",
        "\n",
        "# Step 4: Train a Multiclass Classification Model\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model (optional)\n",
        "# y_pred_train = rf_classifier.predict(X_train)\n",
        "# print(\"Train F1 Score:\", f1_score(y_train, y_pred_train, average='weighted'))\n",
        "\n",
        "# Step 5: Make Predictions on the Test Set\n",
        "# Ensure that the columns of the test dataset match the columns of the training dataset\n",
        "test_df = test_df[X_train.columns]\n",
        "\n",
        "test_predictions = rf_classifier.predict(test_df)\n",
        "\n",
        "# Step 6: Create the Submission File\n",
        "submission_df = pd.DataFrame({'ID': test_df['ID'], 'quality': test_predictions})\n",
        "submission_df.to_csv('multiclass_submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file created successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_data(df):\n",
        "  df['horsepower'] = pd.to_numeric(df['horsepower'], errors=\"coerce\")\n",
        "  return df\n",
        "  #print(df.shape[0],';;;;;;;;;;;;')\n",
        "\n",
        "df =  preprocess_data(df)\n",
        "percent_null(df)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "print(df)\n",
        "###df = preprocess_data(df)\n",
        "Processing categorical variables\n",
        "The function process_categorical performs preprocessing on a pandas DataFrame by converting categorical features into one-hot encoded vectors.\n",
        "The output of this function is the preprocessed DataFrame, with the categorical features now converted into one-hot encoded vectors.\n",
        "[ ]\n",
        "def process_categorical(df):\n",
        "  '''\n",
        "  This function preprocesses a pandas DataFrame by converting the categorical features into one-hot encoded vectors.\n",
        "\n",
        "  Steps:\n",
        "  1. Identify the categorical features in the DataFrame.\n",
        "  2. Use the pandas get_dummies function to convert these categorical features into one-hot encoded vectors.\n",
        "  3. This creates a new binary column for each category/label present in the original columns.\n",
        "\n",
        "  Parameters:\n",
        "  df (pandas.DataFrame): The DataFrame to preprocess. This DataFrame should have 'cylinders', 'model year', 'origin', and 'car name' columns.\n",
        "\n",
        "  Returns:\n",
        "  pandas.DataFrame: The preprocessed DataFrame, with the categorical features converted to one-hot encoded vectors.\n",
        "\n",
        "\n",
        "  '''\n",
        "\n",
        "[ ]\n",
        "###df = process_categorical(_____)\n",
        "[ ]\n",
        "def process_categorical(df):\n",
        "  categorical_features=['cylinders', 'model year', 'origin', 'car name']\n",
        "  one_hot_df = pd.get_dummies(df,columns=categorical_features)\n",
        "  return one_hot_df\n",
        "\n",
        "###print(process_categorical(df))\n",
        "df=process_categorical(df)\n",
        "df.head()\n",
        "\n",
        "\n",
        "Splitting dataset to train and test\n",
        "Write a function to split pandas DataFrame into a training set and a test set, separating features from the target variable 'Sales', and allowing for a customizable ratio for the test set size\n",
        "[ ]\n",
        "def splitting_dataset(df, split_ratio = 0.2):\n",
        "  '''\n",
        "  This function splits a pandas DataFrame into training and testing sets for the purposes of model training and evaluation.\n",
        "\n",
        "  Steps:\n",
        "  1. Define the feature matrix X and the target variable y. In this case, 'mpg' is the target and all other columns are considered features.\n",
        "  2. Use the sklearn's train_test_split function to split the feature matrix and target variable into training and testing sets. The split ratio defines the proportion of the dataset to include in the test split. The random state ensures that the splits generate are reproducible.\n",
        "\n",
        "  Parameters:\n",
        "  df (pandas.DataFrame): The DataFrame to split. This DataFrame should have a 'mpg' column which will be used as the target variable.\n",
        "  split_ratio (float): The proportion of the dataset to include in the test split. Default is 0.2.\n",
        "\n",
        "  Returns:\n",
        "  X_train (pandas.DataFrame): The feature matrix for the training set.\n",
        "  X_test (pandas.DataFrame): The feature matrix for the test set.\n",
        "  y_train (pandas.Series): The target variable for the training set.\n",
        "  y_test (pandas.Series): The target variable for the test set.\n",
        "  '''\n",
        "\n",
        "\n",
        "[ ]\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def splitting_dataset(df, split_ratio = 0.2):\n",
        "  X=df.drop(columns=['mpg'])\n",
        "  y=df['mpg']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=split_ratio, random_state=42)\n",
        "  print(\"X:\",X.shape)\n",
        "  print(\"y:\",y.shape)\n",
        "  print(\"X_train:\",X_train.shape)\n",
        "  print(\"X_test:\",X_test.shape)\n",
        "  print(\"y_train:\",y_train.shape)\n",
        "  print(\"y_test:\",y_test.shape)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = splitting_dataset(df, split_ratio = 0.2)\n",
        "\n",
        "X: (392, 326)\n",
        "y: (392,)\n",
        "X_train: (313, 326)\n",
        "X_test: (79, 326)\n",
        "y_train: (313,)\n",
        "y_test: (79,)\n",
        "Splitting dataset\n",
        "Employ the splitting_dataset function to partition the dataset into training and testing subsets.\n",
        "[ ]\n",
        "###X_train, X_test, y_train, y_test = splitting_dataset(_____)\n",
        "\n",
        "Model fitting\n",
        "The sklearn_multi_regression function is designed to implement a multiple linear regression model utilizing sklearn's LinearRegression. The function initiates a LinearRegression model and fits it on the supplied feature matrix and target variable. This function accepts a feature matrix (x) and a target variable (y), both of which can either be pandas.DataFrame or numpy.ndarray.\n",
        "The function returns a fitted LinearRegression model, which can be employed to make predictions on new data or to examine the coefficients and intercept of the fitted model.\n",
        "[ ]\n",
        "def sklearn_multi_regression(x,y):\n",
        "  '''\n",
        "  This function fits a multiple linear regression model using sklearn's LinearRegression.\n",
        "\n",
        "  Steps:\n",
        "  1. Initialize a LinearRegression model.\n",
        "  2. Fit the model on the provided feature matrix and target variable.\n",
        "\n",
        "  Parameters:\n",
        "  x (pandas.DataFrame or numpy.ndarray): The feature matrix. Each row represents an observation, and each column represents a feature.\n",
        "  y (pandas.Series or numpy.ndarray): The target variable. Each element represents the target value for the corresponding observation in the feature matrix.\n",
        "\n",
        "  Returns:\n",
        "  sklearn.linear_model._base.LinearRegression: The fitted LinearRegression model. This model can be used to make predictions on new data, or to inspect the coefficients and intercept of the fitted model.\n",
        "  '''\n",
        "\n",
        "\n",
        "[ ]\n",
        "def sklearn_multi_regression(x,y):\n",
        "  print(\"innnnnnnnnnnnn on model\")\n",
        "  model=LinearRegression()\n",
        "  print(\"innnnnnnnnnnnn dwon model\")\n",
        "  model.fit(x,y)\n",
        "\n",
        "  print(\"innnnnnnnnnnnn after model\")\n",
        "  return model\n",
        "\n",
        "Find the model performance in test data\n",
        "The performance function is designed to assess the performance of a fitted regression model using a test dataset.\n",
        "\n",
        "The function works in the following steps:\n",
        "\n",
        "It uses the fitted model to generate predictions on the test dataset.\n",
        "It calculates the mean squared error (MSE) and the coefficient of determination (R^2 score) between the actual and predicted target values.\n",
        "It prints the MSE and R^2 score, rounded to two decimal places, to the console.\n",
        "[ ]\n",
        "def performance(model, x_test, y_test):\n",
        "  '''\n",
        "  This function evaluates the performance of a fitted regression model on a test dataset.\n",
        "\n",
        "  Steps:\n",
        "  1. Use the fitted model to make predictions on the test dataset.\n",
        "  2. Compute the mean squared error (MSE) and the coefficient of determination (R^2 score) between the true and predicted target values.\n",
        "  3. Print the MSE and R^2 score to the console, rounded to two decimal places.\n",
        "\n",
        "  Parameters:\n",
        "  model (sklearn estimator): The fitted regression model to evaluate. This model should have a predict method that accepts a feature matrix and returns a vector of predicted target values.\n",
        "  x_test (pandas.DataFrame or numpy.ndarray): The feature matrix for the test dataset. Each row represents an observation, and each column represents a feature.\n",
        "  y_test (pandas.Series or numpy.ndarray): The true target values for the test dataset. Each element represents the true target value for the corresponding observation in the feature matrix.\n",
        "\n",
        "  Returns:\n",
        "  None. However, this function will print the MSE and R^2 score to the console when called.\n",
        "  '''\n",
        "\n",
        "\n",
        "\n",
        "[ ]\n",
        "def performance(model, x_test, y_test):\n",
        "  pred=model.predict(X_test)\n",
        "  mse=mean_squared_error(y_test,pred)\n",
        "  r2 = r2_score(y_test,pred)\n",
        "  print(mse)\n",
        "  print(r2)\n",
        "  return pred, mse, r2\n",
        "\n",
        "splitting_dataset(df, split_ratio = 0.2)\n",
        "[ ]\n",
        "multi_reg = sklearn_multi_regression(_____,_______)\n",
        "performance(_____, ______, _______)\n",
        "[ ]\n",
        "#X_train, X_test, y_train, y_test = splitting_dataset(df, split_ratio = 0.2)\n",
        "#print(X_train, y_train,'lllllllllllllllllllllhhhh')\n",
        "multi_reg = sklearn_multi_regression(X_train, y_train)\n",
        "performance(multi_reg, X_test, y_test)\n",
        "Finding model coefficient\n",
        "The function 'model_coefficients'to create a DataFrame that includes the feature names and corresponding coefficients.\n",
        "\n",
        "The function proceeds in the following manner:\n",
        "\n",
        "A new DataFrame is created that includes two columns - 'features' and 'coefficients'. The 'features' column is filled with the feature names, and the 'coefficients' column is filled with the corresponding coefficients.\n",
        "The function ultimately returns this DataFrame.\n",
        "[ ]\n",
        "def model_coefficients(model, feature_names):\n",
        "  '''\n",
        "  This function extracts the coefficients of a fitted regression model and returns them in a pandas DataFrame.\n",
        "\n",
        "  Steps:\n",
        "  1. Extract the coefficients of the fitted model. The order of the coefficients matches the order of the features in the feature matrix used to fit the model.\n",
        "  2. Create a pandas DataFrame where one column is the feature names and the other column is the corresponding coefficients.\n",
        "\n",
        "  Parameters:\n",
        "  model (sklearn estimator): The fitted regression model. This model should have a coef_ attribute that returns a vector of coefficients.\n",
        "  feature_names (list of str): The names of the features. The order of the names should match the order of the features in the feature matrix used to fit the model.\n",
        "\n",
        "  Returns:\n",
        "  pandas.DataFrame: A DataFrame where one column is the feature names and the other column is the corresponding coefficients. Each row represents a feature and its coefficient.\n",
        "  '''\n",
        "\n",
        "\n",
        "[ ]\n",
        "def model_coefficients(model,feature_names):\n",
        "  coefficients=model.coef_\n",
        "  coef_df=pd.DataFrame({'Feature':feature_names,'coefficients':coefficients})\n",
        "  print(coef_df)\n",
        "  return coef_df\n",
        "\n",
        "[ ]\n",
        "coef_df = model_coefficients(_____, ________)\n",
        "[ ]\n",
        "names = df.columns.tolist()\n",
        "names = names[1:]\n",
        "coef_df = model_coefficients(multi_reg, names)\n",
        "print(coef_df)\n",
        "Sort the coefficient dataframe (highest coefficient first)\n",
        "The sort_df function is used to sort a given pandas DataFrame (df) in descending order based on a specified feature or column (feature).\n",
        "The function returns the input DataFrame sorted in descending order based on the specified feature or column.\n",
        "[ ]\n",
        "def sort_df(df, feature):\n",
        "  '''\n",
        "  This function sorts a pandas DataFrame in descending order based on a specified feature.\n",
        "\n",
        "  Steps:\n",
        "  1. Sort the DataFrame in descending order based on the given feature.\n",
        "\n",
        "  Parameters:\n",
        "  df (pandas.DataFrame): The DataFrame to sort.\n",
        "  feature (str): The name of the feature to sort the DataFrame by.\n",
        "\n",
        "  Returns:\n",
        "  pandas.DataFrame: The sorted DataFrame in descending order based on the specified feature.\n",
        "\n",
        "  '''\n",
        "\n",
        "\n",
        "[ ]\n",
        "def sort_df(df, feature):\n",
        "  df=pd.DataFrame(df)\n",
        "  sorted_df=df.sort_values(by=feature,ascending=False)\n",
        "  return sorted_df\n",
        "[ ]\n",
        "sorted_coef_df = sort_df(_____, \"coefficients\")\n",
        "# check first 10 values\n",
        "sorted_coef_df.head(___)\n",
        "[ ]\n",
        "sorted_coef_df = sort_df(coef_df,\"coefficients\")\n",
        "sorted_coef_df.head()\n",
        "Plotting the model top 10 coefficients\n",
        "The function plotting_top_10_coefficients is designed to create a bar plot representing the top 10 coefficients of a model.\n",
        "[ ]\n",
        "def plotting_top_10_coefficients(df):\n",
        "  '''\n",
        "  This function plots a bar chart of the model coefficients for the top 10 features with the highest importance.\n",
        "\n",
        "  Steps:\n",
        "  1. Create a bar chart using matplotlib to visualize the coefficients of top 10 features.\n",
        "  2. Display the bar chart.\n",
        "\n",
        "  Parameters:\n",
        "  df (pandas.DataFrame): The DataFrame containing the feature names and corresponding model coefficients.\n",
        "\n",
        "  Returns:\n",
        "  None. However, this function will display the bar chart when called.\n",
        "\n",
        "\n",
        "  '''\n",
        "\n",
        "[ ]\n",
        "def plotting_top_10_coefficients(df):\n",
        "  top_10 = df #sorted_coef_df.head(10)\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.bar(top_10['Feature'], top_10['coefficients'], color='blue')\n",
        "  plt.xlabel('Feature')\n",
        "  plt.ylabel('coefficients')\n",
        "  plt.title('Top 10 Coefficients')\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "[ ]\n",
        "##plotting_top_10_coefficients(______)\n",
        "[ ]\n",
        "plotting_top_10_coefficients(sorted_coef_df.head(10))\n",
        "\n",
        "Questions\n",
        "From the analysis you have done above answer the following questions given below:\n",
        "\n",
        "Find the top 10 features with positive impact and top 10 features with negative impact? Do you think the car models play an important role in prediction based on your observation?\n",
        "Colab paid products - Cancel contracts here\n",
        "  2s\n",
        "c"
      ],
      "metadata": {
        "id": "SPjzNPsRnMZ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}