{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM70tzOwbm+hyT9m5zNZMCA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajgit-123/MyProject/blob/master/Artificial_Neural_Networks_IMDBsynopsis_Kaggle_Submitted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBJm_QSkLeMi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Artificial Neural Networks Competition\n",
        "# **Description**\n",
        "Participants will be provided with a dataset containing various input features and corresponding multi-label classifications. The objective is to build a neural network model that can accurately predict the appropriate labels for each data point. However, the unique aspect of this challenge lies in optimizing the hyperparameters and architecture of the neural network to achieve the best possible multi-label classification performance.\n",
        "\n",
        "# **Key Tasks:**\n",
        "\n",
        "# Data Preparation:\n",
        "Contestants will need to preprocess the dataset, including tasks like data cleaning, feature normalization, and encoding of categorical variables. Proper data preparation is crucial for building a reliable multi-label classification model.\n",
        "\n",
        "# Model Building:\n",
        "Participants will create neural network models for multi-label classification. They can experiment with various architectures, such as the number of layers, types of layers, activation functions, and regularization techniques. Model design is a creative and vital aspect of this challenge.\n",
        "# New section\n",
        "# Hyperparameter Tuning:\n",
        " An integral part of this challenge is optimizing the hyperparameters. Contestants will explore various hyperparameters, including learning rate, batch size, the number of epochs, dropout rates, and more. Techniques like grid search, random search can be used to find the best combination.\n",
        "\n",
        "# Validation and Evaluation:\n",
        " Participants will need to implement a robust validation strategy to assess their model's performance. Common metrics for multi-label classification, such as F1-score, precision, recall, and Hamming loss, can be used"
      ],
      "metadata": {
        "id": "am3cpP0zLpAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Flatten, Dropout, LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "q4RPpGVwPi6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading csv file and creating a dataframe\n",
        "- The loading_dataset function is designed to load a dataset from a CSV file into a pandas DataFrame. This function has the ability to handle datasets where values are separated by spaces rather than commas, as indicated by the delim_whitespace=True argument.\n",
        "- This DataFrame, df, is then returned as the output of the function."
      ],
      "metadata": {
        "id": "l6_QL9yRMdsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "train_file_path='/content/drive/MyDrive/ADSA010/ANN-IMDB-Assign/train_mpst.csv'\n",
        "test_file_path='/content/drive/MyDrive/ADSA010/ANN-IMDB-Assign/test.csv'\n",
        "val_file_path='/content/drive/MyDrive/ADSA010/ANN-IMDB-Assign/val.csv'\n",
        "#Creating dataframe\n",
        "train_df =pd.read_csv(train_file_path)\n",
        "test_df=pd.read_csv(test_file_path)\n",
        "val_df=pd.read_csv(val_file_path)\n",
        "print(train_df.head)\n",
        "print(train_df.shape)\n",
        "print(val_df.shape)\n",
        "\n",
        "\n",
        "df_testcopy = test_df\n",
        "df_testcopy.rename(columns={'imdb_id':'ID'}, inplace=True)"
      ],
      "metadata": {
        "id": "WpA9kYWLPltc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85dbedbc-154d-4ea0-96c1-4b588fcc1453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "<bound method NDFrame.head of         imdb_id                                          title  \\\n",
            "0     tt0057603                        I tre volti della paura   \n",
            "1     tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n",
            "2     tt0113862                             Mr. Holland's Opus   \n",
            "3     tt0249380                                      Baise-moi   \n",
            "4     tt0408790                                     Flightplan   \n",
            "...         ...                                            ...   \n",
            "9484  tt0045053                          The Prisoner of Zenda   \n",
            "9485  tt0074646                                     Hot Potato   \n",
            "9486  tt0102592                                 One False Move   \n",
            "9487  tt1371159                                     Iron Man 2   \n",
            "9488  tt0063443                                     Play Dirty   \n",
            "\n",
            "                                          plot_synopsis synopsis_source  \\\n",
            "0     Note: this synopsis is for the orginal Italian...            imdb   \n",
            "1     Two thousand years ago, Nhagruul the Foul, a s...            imdb   \n",
            "2     Glenn Holland, not a morning person by anyone'...            imdb   \n",
            "3     Baise-moi tells the story of Nadine and Manu w...       wikipedia   \n",
            "4     Kyle Pratt (Jodie Foster) is a propulsion engi...            imdb   \n",
            "...                                                 ...             ...   \n",
            "9484  On his deathbed, the king of Ruritania announc...       wikipedia   \n",
            "9485  Hot Potato begins in Chang Lan, a fictional co...       wikipedia   \n",
            "9486  Three criminals, Ray, Pluto and Fantasia (Ray'...       wikipedia   \n",
            "9487  In Russia, the media covers Tony Stark's discl...       wikipedia   \n",
            "9488  During the North African Campaign in World War...       wikipedia   \n",
            "\n",
            "      absurd  action  adult comedy  allegory  alternate history  \\\n",
            "0          0       0             0         0                  0   \n",
            "1          0       0             0         0                  0   \n",
            "2          0       0             0         0                  0   \n",
            "3          0       0             0         0                  0   \n",
            "4          0       1             0         0                  0   \n",
            "...      ...     ...           ...       ...                ...   \n",
            "9484       0       1             0         0                  0   \n",
            "9485       0       0             0         0                  0   \n",
            "9486       0       0             0         0                  0   \n",
            "9487       0       0             0         0                  0   \n",
            "9488       0       0             0         0                  0   \n",
            "\n",
            "      alternate reality  ...  sentimental  storytelling  stupid  suicidal  \\\n",
            "0                     0  ...            0             0       0         0   \n",
            "1                     0  ...            0             0       0         0   \n",
            "2                     0  ...            0             0       1         0   \n",
            "3                     0  ...            0             0       0         0   \n",
            "4                     0  ...            0             0       0         0   \n",
            "...                 ...  ...          ...           ...     ...       ...   \n",
            "9484                  0  ...            0             0       0         0   \n",
            "9485                  0  ...            0             0       0         0   \n",
            "9486                  0  ...            0             0       0         0   \n",
            "9487                  0  ...            0             0       0         0   \n",
            "9488                  0  ...            0             0       0         0   \n",
            "\n",
            "      suspenseful  thought-provoking  tragedy  violence  western  whimsical  \n",
            "0               0                  0        0         0        0          0  \n",
            "1               0                  0        0         1        0          0  \n",
            "2               0                  0        0         0        0          0  \n",
            "3               0                  0        0         1        0          0  \n",
            "4               1                  0        0         0        0          0  \n",
            "...           ...                ...      ...       ...      ...        ...  \n",
            "9484            0                  0        0         0        0          0  \n",
            "9485            0                  0        0         0        0          0  \n",
            "9486            1                  0        0         1        0          0  \n",
            "9487            0                  0        0         1        0          0  \n",
            "9488            0                  0        0         0        0          0  \n",
            "\n",
            "[9489 rows x 75 columns]>\n",
            "(9489, 75)\n",
            "(2373, 75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding percentage of null values\n",
        "- The function percent_null is designed to compute and display the percentage of null or missing values in each column of a given pandas DataFrame."
      ],
      "metadata": {
        "id": "-PNM0L2LMl7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def percent_null(df):\n",
        "#   percentage_ofnull=(train_df.isnull().sum()*100)/len(df)\n",
        "#   return percentage_ofnull\n",
        "# print(percent_null(train_df))"
      ],
      "metadata": {
        "id": "3cXJ0-eZUAZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def format_data(text):\n",
        "    text = re.sub(\"\\'\", \"\", text)\n",
        "    text = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
        "    text = ' '.join(text.split())\n",
        "    text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "ZBj7oJ_72LqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TOixL1NrsYP",
        "outputId": "deaf24f1-22a1-474a-d995-b89d6fcb4973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9489, 75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess data\n",
        "- The preprocess_data function is designed to perform several preprocessing tasks on a given pandas DataFrame. Specifically, it targets the DataFrame's 'horsepower' column for conversion to numeric values, checks and prints the percentage of null values in each column, and eliminates rows containing null values."
      ],
      "metadata": {
        "id": "fYhelQSNMqbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['plot_synopsis'] = train_df['plot_synopsis'].apply(lambda txt: format_data(txt))\n",
        "test_df['plot_synopsis'] = train_df['plot_synopsis'].apply(lambda txt: format_data(txt))\n",
        "val_df['plot_synopsis'] = train_df['plot_synopsis'].apply(lambda txt: format_data(txt))\n",
        "print(train_df.columns)\n",
        "print(test_df.columns)\n",
        "print(val_df.columns)\n"
      ],
      "metadata": {
        "id": "6iXwJ82D1R2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f704c621-c6cc-4b6f-8309-871602ab166f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['imdb_id', 'title', 'plot_synopsis', 'synopsis_source', 'absurd',\n",
            "       'action', 'adult comedy', 'allegory', 'alternate history',\n",
            "       'alternate reality', 'anti war', 'atmospheric', 'autobiographical',\n",
            "       'avant garde', 'blaxploitation', 'bleak', 'boring', 'brainwashing',\n",
            "       'christian film', 'claustrophobic', 'clever', 'comedy', 'comic',\n",
            "       'cruelty', 'cult', 'cute', 'dark', 'depressing', 'dramatic',\n",
            "       'entertaining', 'fantasy', 'feel-good', 'flashback', 'good versus evil',\n",
            "       'gothic', 'grindhouse film', 'haunting', 'historical',\n",
            "       'historical fiction', 'home movie', 'horror', 'humor', 'insanity',\n",
            "       'inspiring', 'intrigue', 'magical realism', 'melodrama', 'murder',\n",
            "       'mystery', 'neo noir', 'non fiction', 'paranormal', 'philosophical',\n",
            "       'plot twist', 'pornographic', 'prank', 'psychedelic', 'psychological',\n",
            "       'queer', 'realism', 'revenge', 'romantic', 'sadist', 'satire', 'sci-fi',\n",
            "       'sentimental', 'storytelling', 'stupid', 'suicidal', 'suspenseful',\n",
            "       'thought-provoking', 'tragedy', 'violence', 'western', 'whimsical'],\n",
            "      dtype='object')\n",
            "Index(['ID', 'title', 'plot_synopsis', 'synopsis_source'], dtype='object')\n",
            "Index(['imdb_id', 'title', 'plot_synopsis', 'synopsis_source', 'absurd',\n",
            "       'action', 'adult comedy', 'allegory', 'alternate history',\n",
            "       'alternate reality', 'anti war', 'atmospheric', 'autobiographical',\n",
            "       'avant garde', 'blaxploitation', 'bleak', 'boring', 'brainwashing',\n",
            "       'christian film', 'claustrophobic', 'clever', 'comedy', 'comic',\n",
            "       'cruelty', 'cult', 'cute', 'dark', 'depressing', 'dramatic',\n",
            "       'entertaining', 'fantasy', 'feel-good', 'flashback', 'good versus evil',\n",
            "       'gothic', 'grindhouse film', 'haunting', 'historical',\n",
            "       'historical fiction', 'home movie', 'horror', 'humor', 'insanity',\n",
            "       'inspiring', 'intrigue', 'magical realism', 'melodrama', 'murder',\n",
            "       'mystery', 'neo noir', 'non fiction', 'paranormal', 'philosophical',\n",
            "       'plot twist', 'pornographic', 'prank', 'psychedelic', 'psychological',\n",
            "       'queer', 'realism', 'revenge', 'romantic', 'sadist', 'satire', 'sci-fi',\n",
            "       'sentimental', 'storytelling', 'stupid', 'suicidal', 'suspenseful',\n",
            "       'thought-provoking', 'tragedy', 'violence', 'western', 'whimsical'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing categorical variables\n",
        "- The function process_categorical performs preprocessing on a pandas DataFrame by converting categorical features into one-hot encoded vectors.\n",
        "- The output of this function is the preprocessed DataFrame, with the categorical features now converted into one-hot encoded vectors."
      ],
      "metadata": {
        "id": "VGIPZPxZMuoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)"
      ],
      "metadata": {
        "id": "s_4CHfaq3HUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df.shape)\n",
        "X_train = train_df['plot_synopsis'].values\n",
        "X_test = test_df['plot_synopsis'].values\n",
        "X_val = val_df['plot_synopsis'].values\n",
        "y_train = train_df.iloc[:, 4:].values\n",
        "\n",
        "\n",
        "y_val = val_df.iloc[:, 4:].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBayhHZj3oWM",
        "outputId": "4b7d6a16-9a50-4796-ac03-81e988baabfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2966, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain_TfidfVect = tfidf_vectorizer.fit_transform(X_train)\n",
        "xval_TfidfVect = tfidf_vectorizer.transform(X_val)\n",
        "xtest_TfidfVect = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "f0WAEhrU4tru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "Logreg = LogisticRegression()\n",
        "OnevsRestclf = OneVsRestClassifier(Logreg)\n",
        "OnevsRestclf.fit(xtrain_TfidfVect, y_train)\n",
        "\n",
        "\n",
        "y_pred = OnevsRestclf.predict(xval_TfidfVect)\n",
        "y_pred_test = OnevsRestclf.predict(xtest_TfidfVect)\n",
        "\n",
        "print(y_pred_test.shape)\n",
        "print(df_testcopy.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ENpJ_i65QGm",
        "outputId": "e625e520-e2b3-4e72-bfe9-260dfa3913d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2966, 71)\n",
            "(2966, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_op_cols = df_testcopy\n",
        "\n",
        "df_op_cols[['absurd',\n",
        "       'action', 'adult comedy', 'allegory', 'alternate history',\n",
        "       'alternate reality', 'anti war', 'atmospheric', 'autobiographical',\n",
        "       'avant garde', 'blaxploitation', 'bleak', 'boring', 'brainwashing',\n",
        "       'christian film', 'claustrophobic', 'clever', 'comedy', 'comic',\n",
        "       'cruelty', 'cult', 'cute', 'dark', 'depressing', 'dramatic',\n",
        "       'entertaining', 'fantasy', 'feel-good', 'flashback', 'good versus evil',\n",
        "       'gothic', 'grindhouse film', 'haunting', 'historical',\n",
        "       'historical fiction','home movie', 'horror', 'humor', 'insanity',\n",
        "       'inspiring', 'intrigue', 'magical realism', 'melodrama', 'murder',\n",
        "       'mystery', 'neo noir', 'non fiction', 'paranormal', 'philosophical',\n",
        "       'plot twist', 'pornographic', 'prank', 'psychedelic', 'psychological',\n",
        "       'queer', 'realism', 'revenge', 'romantic', 'sadist', 'satire', 'sci-fi',\n",
        "       'sentimental', 'storytelling', 'stupid', 'suicidal', 'suspenseful',\n",
        "       'thought-provoking', 'tragedy', 'violence', 'western', 'whimsical']] = y_pred_test\n",
        "\n",
        "submission_df = df_op_cols.filter(['ID','absurd',\n",
        "       'action', 'adult comedy', 'allegory', 'alternate history',\n",
        "       'alternate reality', 'anti war', 'atmospheric', 'autobiographical',\n",
        "       'avant garde', 'blaxploitation', 'bleak', 'boring', 'brainwashing',\n",
        "       'christian film', 'claustrophobic', 'clever', 'comedy', 'comic',\n",
        "       'cruelty', 'cult', 'cute', 'dark', 'depressing', 'dramatic',\n",
        "       'entertaining', 'fantasy', 'feel-good', 'flashback', 'good versus evil',\n",
        "       'gothic', 'grindhouse film', 'haunting', 'historical',\n",
        "       'historical fiction', 'home movie', 'horror', 'humor', 'insanity',\n",
        "       'inspiring', 'intrigue', 'magical realism', 'melodrama', 'murder',\n",
        "       'mystery', 'neo noir', 'non fiction', 'paranormal', 'philosophical',\n",
        "       'plot twist', 'pornographic', 'prank', 'psychedelic', 'psychological',\n",
        "       'queer', 'realism', 'revenge', 'romantic', 'sadist', 'satire', 'sci-fi',\n",
        "       'sentimental', 'storytelling', 'stupid', 'suicidal', 'suspenseful',\n",
        "       'thought-provoking', 'tragedy', 'violence', 'western', 'whimsical'])\n",
        "submission_df.to_csv('submission-imdb.csv', index=False)\n"
      ],
      "metadata": {
        "id": "YSd1UEBy7yCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_df.shape)\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# cols_to_convert=train_df[['imdb_id','title','plot_synopsis','synopsis_source']]\n",
        "# ext_data = cols_to_convert.apply(lambda x: ' '.join(x), axis=1)\n",
        "# # Initialize CountVectorizer\n",
        "# count_vectorizer = CountVectorizer()\n",
        "\n",
        "# # Fit and transform the text data\n",
        "# bow_matrix = count_vectorizer.fit_transform(ext_data)\n",
        "\n",
        "# # Get the feature names (vocabulary)\n",
        "# feature_names = count_vectorizer.get_feature_names_out()\n",
        "\n",
        "# # Convert the BoW matrix to a DataFrame for better visualization (optional)\n",
        "# bow_df = pd.DataFrame(bow_matrix.toarray(), columns=feature_names)\n",
        "\n",
        "# # Display the BoW DataFrame\n",
        "# print(bow_df)\n",
        "\n",
        "# X = bow_df.values  # Features\n",
        "# y=train_df.iloc[:, [0] + list(range(4, 74))]\n",
        "# print(y.shape)\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(bow_matrix, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the RandomForestClassifier\n",
        "# rf_clf = RandomForestClassifier()\n",
        "\n",
        "# # Training the classifier\n",
        "# rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# # Evaluating the classifier\n",
        "# accuracy = rf_clf.score(X_test, y_test)/.\n",
        "# print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# non_numeric_columns = train_df.iloc[:, [1,3]].columns.tolist()  # Assuming non-numeric columns are at index 1\n",
        "# for column in non_numeric_columns:\n",
        "#     train_df[column] = train_df[column].astype(str)\n",
        "\n",
        "# def process_categorical(train_df):\n",
        "#   categorical_features=['imdb_id','title','plot_synopsis','synopsis_source']\n",
        "#   one_hot_df = pd.get_dummies(train_df,columns=categorical_features)\n",
        "#   return one_hot_df\n",
        "\n",
        "# df_processed=process_categorical(train_df)\n",
        "# X_train=train_df[['title','plot_synopsis','synopsis_source']]\n",
        "# print(X_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "# transformers = []\n",
        "# for column in non_numeric_columns:\n",
        "#     transformers.append((column, OneHotEncoder(), [column]))\n",
        "\n",
        "# col_transformer = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
        "# X_transformed = col_transformer.fit_transform(X_train)\n",
        "\n",
        "# print(X_transformed.head)\n",
        "# print(train_df['plot_synopsis'].unique())\n",
        "# scaler = StandardScaler()\n",
        "# X_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# print(test_df.shape)\n",
        "# X_t=test_df[['title','plot_synopsis','synopsis_source']]\n",
        "# print(X_t.head)\n",
        "\n",
        "# y_t=test_df.iloc[:, [0] + list(range(4, 74))]\n",
        "# print(y_t.head)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "1kySbnef1WD5",
        "outputId": "7de3a9ca-7050-41ae-bca3-f4795c9686b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9489, 75)\n",
            "      00  000  0000  00000006  0008  000bc  000th  001  0014  002  ...  風林館高校  \\\n",
            "0      0    0     0         0     0      0      0    0     0    0  ...      0   \n",
            "1      0    0     0         0     0      0      0    0     0    0  ...      0   \n",
            "2      0    0     0         0     0      0      0    0     0    0  ...      0   \n",
            "3      0    0     0         0     0      0      0    0     0    0  ...      0   \n",
            "4      0    2     0         0     0      0      0    0     0    0  ...      0   \n",
            "...   ..  ...   ...       ...   ...    ...    ...  ...   ...  ...  ...    ...   \n",
            "9484   0    0     0         0     0      0      0    0     0    0  ...      0   \n",
            "9485   0    0     0         0     0      0      0    0     0    0  ...      0   \n",
            "9486   0    0     0         0     0      0      0    0     0    0  ...      0   \n",
            "9487   0    0     0         0     0      0      0    0     0    0  ...      0   \n",
            "9488   0    0     0         0     0      0      0    0     0    0  ...      0   \n",
            "\n",
            "      馮婉瑜  駒王学園  骨喰いの井戸  魔界  黄薔薇  黒渦町  黒髪  齊天大聖  齐天大圣  \n",
            "0       0     0       0   0    0    0   0     0     0  \n",
            "1       0     0       0   0    0    0   0     0     0  \n",
            "2       0     0       0   0    0    0   0     0     0  \n",
            "3       0     0       0   0    0    0   0     0     0  \n",
            "4       0     0       0   0    0    0   0     0     0  \n",
            "...   ...   ...     ...  ..  ...  ...  ..   ...   ...  \n",
            "9484    0     0       0   0    0    0   0     0     0  \n",
            "9485    0     0       0   0    0    0   0     0     0  \n",
            "9486    0     0       0   0    0    0   0     0     0  \n",
            "9487    0     0       0   0    0    0   0     0     0  \n",
            "9488    0     0       0   0    0    0   0     0     0  \n",
            "\n",
            "[9489 rows x 112381 columns]\n",
            "(9489, 71)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'<' not supported between instances of 'int' and 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-629761c5ac34>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Training the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mrf_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Evaluating the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mTarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     if y_type not in [\n\u001b[1;32m    212\u001b[0m         \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be class 'SparseSeries' or 'SparseArray'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_multilabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    189\u001b[0m         )\n\u001b[1;32m    190\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         return len(labels) < 3 and (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36munique_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         ret = _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0m\u001b[1;32m    275\u001b[0m                         equal_nan=equal_nan)\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting dataset to train and test\n",
        "-  Write a function to split pandas DataFrame into a training set and a test set, separating features from the target variable 'Sales', and allowing for a customizable ratio for the test set size"
      ],
      "metadata": {
        "id": "OVD9pPjVMz2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into features and target\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Define the neural network architecture\n",
        "def create_model(learning_rate=0.001, embedding_dim=128, lstm_units=64, dropout_rate=0.2):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "    model.add(LSTM(lstm_units, dropout=dropout_rate))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "KSKF5gMAExbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model fitting\n",
        "- The sklearn_multi_regression function is designed to implement a multiple linear regression model utilizing sklearn's LinearRegression. The function initiates a LinearRegression model and fits it on the supplied feature matrix and target variable. This function accepts a feature matrix (x) and a target variable (y), both of which can either be pandas.DataFrame or numpy.ndarray.\n",
        "- The function returns a fitted LinearRegression model, which can be employed to make predictions on new data or to examine the coefficients and intercept of the fitted model."
      ],
      "metadata": {
        "id": "2Ex8N8Q8M3Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}"
      ],
      "metadata": {
        "id": "hu26pLvUjPk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find the model performance in test data\n",
        "The performance function is designed to assess the performance of a fitted regression model using a test dataset.\n",
        "\n",
        "The function works in the following steps:\n",
        "\n",
        "1. It uses the fitted model to generate predictions on the test dataset.\n",
        "2. It calculates the mean squared error (MSE) and the coefficient of determination (R^2 score) between the actual and predicted target values.\n",
        "3. It prints the MSE and R^2 score, rounded to two decimal places, to the console."
      ],
      "metadata": {
        "id": "zr7mqlpDM6uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing Randomized Search Cross Validation\n",
        "random_search = RandomizedSearchCV(estimator=classifier, param_distributions=param_grid, n_iter=10, cv=3, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Getting the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Training the model with the best parameters\n",
        "best_rf_clf = RandomForestClassifier(**best_params)\n",
        "best_rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating the model\n",
        "accuracy = best_rf_clf.score(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "u_LE8vqmlRU6",
        "outputId": "0449f06a-8af2-4763-d940-0f363d55cabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'<' not supported between instances of 'int' and 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-f00f2620cc88>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Performing Randomized Search Cross Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrandom_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Getting the best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0mcv_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[0;34m(cv, y, classifier)\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0mclassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2444\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2445\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2446\u001b[0m         ):\n\u001b[1;32m   2447\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be class 'SparseSeries' or 'SparseArray'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_multilabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    189\u001b[0m         )\n\u001b[1;32m    190\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         return len(labels) < 3 and (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36munique_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         ret = _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0m\u001b[1;32m    275\u001b[0m                         equal_nan=equal_nan)\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t0ILaIPzLzDL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}